<p style="font-family: 'Amiri', serif; font-size: 3rem; color: black; text-align: center; margin: 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3); background-color: cyan; padding: 20px; border-radius: 20px; border: 7px solid #2ca02c; width: 95%;">Sepsis Survival Prediction</p>

## üéØ Goal

The goal of this project is to predict the survival of patients with sepsis using machine learning models based on clinical records.

## üßµ Dataset

The dataset used for this project is sourced from [Sepsis Survival Minimal Clinical Records on Kaggle](https://www.kaggle.com/datasets/joebeachcapital/sepsis-survival-minimal-clinical-records).

## üßæ Description

This project involves the analysis of clinical records to predict the survival of patients with sepsis. It includes data preprocessing, model training, evaluation, and comparison of multiple algorithms to determine the most accurate model.

## üßÆ What I had done!

1. **Data Collection**: Acquired the clinical records dataset for sepsis survival prediction.
2. **Data Preprocessing**: Cleaned and prepared the data for analysis.
3. **Exploratory Data Analysis (EDA)**: Visualized the data to understand the distribution and relationships between variables.
4. **Model Training**: Implemented various machine learning models.
5. **Model Evaluation**: Evaluated the performance of each model using accuracy scores.
6. **Model Comparison**: Compared the models to identify the best performer.
7. **Visualization**: Plotted confusion matrices for model predictions.

## üöÄ Models Implemented

1. **Random Forest**: Selected for its robustness and ability to handle complex datasets.
2. **XGBoost**: Chosen for its high performance and scalability.
3. **Logistic Regression**: A baseline model for comparison.
4. **Gradient Boosting**: Implemented for its accuracy in classification tasks.
5. **AdaBoost**: Chosen for its ability to improve the performance of weak classifiers.
6. **CatBoost**: Selected for its efficiency with categorical data (Accuracy: 90.93%).
7. **LightGBM**: Chosen for its fast training speed and low memory usage.
8. **K-Nearest Neighbors (KNN)**: Implemented for its simplicity and effectiveness (Accuracy: 90.46%).
9. **Support Vector Machine (SVM)**: Utilized for its ability to handle complex relationships in data.
10. **Decision Tree**: Implemented for its interpretability and ability to handle both numerical and categorical data.

## üìö Libraries Needed

- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn
- xgboost
- catboost
- lightgbm

## üìä Exploratory Data Analysis Results

![EDA Image 1](https://github.com/adi271001/ML-Crate/blob/sepsis-survival-prediction/Sepsis%20Survival%20Prediction/Images/__results___10_0.png?raw=true)
![EDA Image 2](https://github.com/adi271001/ML-Crate/blob/sepsis-survival-prediction/Sepsis%20Survival%20Prediction/Images/__results___11_1.png?raw=true)
![EDA Image 3](https://github.com/adi271001/ML-Crate/blob/sepsis-survival-prediction/Sepsis%20Survival%20Prediction/Images/__results___11_3.png?raw=true)
![EDA Image 3](https://github.com/adi271001/ML-Crate/blob/sepsis-survival-prediction/Sepsis%20Survival%20Prediction/Images/__results___11_5.png?raw=true)
![EDA Image 3](https://github.com/adi271001/ML-Crate/blob/sepsis-survival-prediction/Sepsis%20Survival%20Prediction/Images/__results___11_7.png?raw=true)
![EDA Image 3](https://github.com/adi271001/ML-Crate/blob/sepsis-survival-prediction/Sepsis%20Survival%20Prediction/Images/__results___12_1.png?raw=true)
![EDA Image 3](https://github.com/adi271001/ML-Crate/blob/sepsis-survival-prediction/Sepsis%20Survival%20Prediction/Images/__results___13_1.png?raw=true)
![EDA Image 3](https://github.com/adi271001/ML-Crate/blob/sepsis-survival-prediction/Sepsis%20Survival%20Prediction/Images/__results___14_2.png?raw=true)

## üìà Performance of the Models based on the Accuracy Scores

- **Random Forest**: 90.92%
- **XGBoost**: 90.92%
- **Logistic Regression**: 90.92%
- **Gradient Boosting**: 90.92%
- **AdaBoost**: 90.92%
- **CatBoost**: 90.93%
- **LightGBM**: 90.92%
- **K-Nearest Neighbors (KNN)**: 90.46%
- **Support Vector Machine (SVM)**: 90.92%
- **Decision Tree**: 90.92%

## üì¢ Conclusion

The project successfully implemented and evaluated various machine learning models for predicting sepsis survival using clinical records. CatBoost emerged as the best performer with an accuracy of 90.93%, closely followed by other models at 90.92% accuracy. K-Nearest Neighbors (KNN) also performed well with an accuracy of 90.46%.

‚úíÔ∏è Your Signature  
Aditya D
* Github: https://wwww.github.com/adi271001
* LInkedin: https://www.linkedin.com/in/aditya-d-23453a179/
* Topmate: https://topmate.io/aditya_d/
* Twitter: https://x.com/ADITYAD29257528
